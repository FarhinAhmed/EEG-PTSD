{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import pylab as pl\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.svm import OneClassSVM\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 16)\n",
    "\n",
    "LARGE_FIGSIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['attention', 'delta', 'highAlpha', 'highBeta', 'lowAlpha', 'lowBeta',\n",
       "       'lowGamma', 'meditation', 'midGamma', 'recording_time', 'session_id',\n",
       "       'theta', 'user_activity_id', 'user_id', 'user_mental_state_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#first, read the csv file as a df\n",
    "eeg_df = pd.read_csv(\"eeg_dataset\",parse_dates = True)\n",
    "eeg_df['recording_time'] = eeg_df['recording_time'].astype(\"datetime64[ms]\")\n",
    "eeg_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We will produce grpahs for each user:\n",
    "#A graph will be produced for a single user for a single attribute and a constant mental state showing that particular attribute for\n",
    "#the different physical states\n",
    "def graph_given_users_on_the_mentioned_attributes_user_activities_mental_states(user_ids,excluded_attributes,included_user_activities,included_mental_states):\n",
    "    #first, keep the attributes we are interested in\n",
    "    columns = eeg_df.columns\n",
    "    columns = [col for col in columns if col not in excluded_attributes]\n",
    "    #print(columns)\n",
    "    temp_df = eeg_df[columns]\n",
    "    #Then filter out the excess user activity attributes\n",
    "    temp_df = temp_df[temp_df['user_activity_id'].isin(included_user_activities)]\n",
    "    #print(temp_df.head())\n",
    "    #print(temp_df['user_activity_id'].unique())\n",
    "    #Now keep onlythe given mental state ids\n",
    "    temp_df = temp_df[temp_df['user_mental_state_id'].isin(included_mental_states)]\n",
    "    \n",
    "    #And of course, filter the users\n",
    "    temp_df = temp_df[temp_df['user_id'].isin(user_ids)]\n",
    "    #We will expand this method a lot in the future iA\n",
    "    \n",
    "    \n",
    "    #print(temp_df['user_activity_id'].unique())\n",
    "    #print(temp_df['user_mental_state_id'].unique())\n",
    "    #print(temp_df['user_id'].unique())\n",
    "    #print(temp_df['user_activity_id'].unique())\n",
    "    #print(temp_df.columns)\n",
    "    #draw_graph(0,5,['attention', 'meditation','delta', 'highAlpha', 'highBeta'],5,temp_df)\n",
    "    drawValForEachAttrForAllActivities(0,5,['attention', 'meditation','delta', 'highAlpha', 'highBeta'],[5,7,8],temp_df)\n",
    "    return temp_df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drawValForEachAttrForAllActivities' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-283f1c15b577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mincluded_mental_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0muser_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtemp_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_given_users_on_the_mentioned_attributes_user_activities_mental_states\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mexcluded_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mincluded_user_activities\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mincluded_mental_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-13ec8cc1c5f6>\u001b[0m in \u001b[0;36mgraph_given_users_on_the_mentioned_attributes_user_activities_mental_states\u001b[0;34m(user_ids, excluded_attributes, included_user_activities, included_mental_states)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#print(temp_df.columns)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#draw_graph(0,5,['attention', 'meditation','delta', 'highAlpha', 'highBeta'],5,temp_df)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdrawValForEachAttrForAllActivities\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'meditation'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'delta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'highAlpha'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'highBeta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'drawValForEachAttrForAllActivities' is not defined"
     ]
    }
   ],
   "source": [
    "#included_attributes = [ 'attention', 'delta', 'highAlpha', 'highBeta', 'lowAlpha', 'lowBeta',\n",
    "       #'lowGamma', 'meditation', 'midGamma','theta']\n",
    "excluded_attributes = [ 'lowAlpha', 'lowBeta','lowGamma','midGamma']\n",
    "included_user_activities = [5,7,8]\n",
    "included_mental_states = [5]\n",
    "user_ids = [0]\n",
    "temp_df = graph_given_users_on_the_mentioned_attributes_user_activities_mental_states(user_ids,excluded_attributes,included_user_activities,included_mental_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we need to graph. \n",
    "def draw_graph(user_id,mental_state,all_attributes,all_activities,cur_df):\n",
    "    cur_df = cur_df[all_attributes]\n",
    "    plt.figure(); cur_df.plot();\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drawValForEachAttrForAllActivities(user_id,mental_state,attributes_to_draw,all_activities,cur_df):\n",
    "    df_map = {}\n",
    "    for att in attributes_to_draw:\n",
    "        df_map[att] = pd.DataFrame()\n",
    "    #print(df_map)\n",
    "    \n",
    "    grouped_by_activity = cur_df.groupby(\"user_activity_id\")\n",
    "    \n",
    "    for group_name,sub_df in grouped_by_activity:\n",
    "        #print(sub_df)\n",
    "        #print(group_name)\n",
    "        for att in attributes_to_draw:\n",
    "            col_name = att + str(group_name)\n",
    "            #print(col_name)\n",
    "            #print(sub_df[att])\n",
    "            df_map[att][col_name] = sub_df[att].reset_index(drop=True)\n",
    "    #Now replace all NAN with interpolation\n",
    "    for att in attributes_to_draw:\n",
    "        df_map[att] = df_map[att].interpolate()\n",
    "        #plt.figure(); df_map[att].plot(logy = True);\n",
    "        #break\n",
    "        print(att,df_map[att].describe())\n",
    "    \n",
    "        \n",
    "    #print(df_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def q_25(df_column):\n",
    "    return df_column.quantile(0.25)\n",
    "def q_50(df_column):\n",
    "    return df_column.quantile(0.5)\n",
    "def q_75(df_column):\n",
    "    return df_column.quantile(0.75)\n",
    "def prepare_dataset(cur_df):\n",
    "        func = {'attention':['mean','std','max','min',q_25,q_50,q_75], 'meditation':['mean','std','max','min',q_25,q_50,q_75],'delta':['mean','std','max','min',q_25,q_50,q_75], 'highAlpha':['mean','std','max','min',q_25,q_50,q_75], 'highBeta':['mean','std','max','min',q_25,q_50,q_75], 'lowAlpha':['mean','std','max','min',q_25,q_50,q_75], 'lowBeta':['mean','std','max','min',q_25,q_50,q_75],\n",
    "        'lowGamma':['mean','std','max','min',q_25,q_50,q_75],'midGamma':['mean','std','max','min',q_25,q_50,q_75],'theta':['mean','std','max','min',q_25,q_50,q_75] }\n",
    "        #func = {'attention':['mean','std',q_25,q_50,q_75]}\n",
    "        att_med = cur_df.groupby(\"user_id\").agg(func)\n",
    "        \n",
    "        return att_med,att_med.values\n",
    "        \n",
    "        \n",
    "            #print(group_name,sub_df)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 70)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_df,dataset = prepare_dataset(eeg_df)\n",
    "#refined_df.head()\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eeg_df['attention'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_clustering(num_clusters,dataset):\n",
    "    best_score = -1000\n",
    "    best_model = None\n",
    "\n",
    "\n",
    "    for i in range(100):\n",
    "    \n",
    "        kmeans_model = KMeans(n_clusters=num_clusters, random_state=1).fit(dataset)\n",
    "   \n",
    "        score = metrics.silhouette_score(dataset, kmeans_model.labels_, metric='euclidean')\n",
    "    \n",
    "        if(score > best_score):\n",
    "            best_score = score\n",
    "            best_model = kmeans_model\n",
    "    print(best_score)      \n",
    "\n",
    "\n",
    "    labels = best_model.labels_\n",
    "    #print(labels)\n",
    "    print(best_model.cluster_centers_)\n",
    "    #plt.scatter(best_model.cluster_centers_[:,0],best_model.cluster_centers_[:,1])\n",
    "    #plt.xlabel(\"CV\")\n",
    "    #plt.ylabel(\"Dailty average sales\")\n",
    "    #plt.scatter(np_array_of_average_and_var[:,0], np_array_of_average_and_var[:,1], c=labels)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run_clustering(4,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def anomally_detection(dataset):\n",
    "    classifiers = {\n",
    " \n",
    "    \n",
    "    \n",
    "    \"OCSVM\": OneClassSVM(nu=0.261, gamma=0.05)\n",
    "        }\n",
    "    #\"Robust covariance\": EllipticEnvelope(contamination=outliers_fraction)}\n",
    "    # Learn a frontier for outlier detection with several classifiers\n",
    "    #xx1, yy1 = np.meshgrid(np.linspace(-8, 28, 500), np.linspace(3, 40, 500))\n",
    "    #x2, yy2 = np.meshgrid(np.linspace(3, 10, 500), np.linspace(-5, 45, 500))\n",
    "    \n",
    "    for i, (clf_name, clf) in enumerate(classifiers.items()):\n",
    "    \n",
    "        clf.fit(dataset)\n",
    "        #Z1 = clf.decision_function(np.c_[xx1.ravel(), yy1.ravel()])\n",
    "        #Z1 = Z1.reshape(xx1.shape)\n",
    "        return clf\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anomally_clf = anomally_detection(dataset)\n",
    "anomally_clf.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
